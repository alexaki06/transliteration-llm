# ğŸš€ Complete System Setup Guide

Get the entire Transliteration LLM system running end-to-end!

## Overview

The system consists of two main components:
1. **Backend API** - FastAPI transliteration service
2. **Frontend GUI** - Streamlit web application

---

## âš¡ Quick Start (5 Minutes)

### Terminal 1: Start Backend API

```bash
cd backend
pip install -r requirements.txt
python -m uvicorn main:app --reload
```

Expected output:
```
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Application startup complete
```

âœ… **API is running at**: http://localhost:8000  
âœ… **Docs available at**: http://localhost:8000/docs

### Terminal 2: Start Frontend

```bash
cd frontend
pip install -r requirements.txt
streamlit run app.py
```

Expected output:
```
  Local URL: http://localhost:8501
  Network URL: http://192.168.x.x:8501
```

âœ… **App is running at**: http://localhost:8501  
âœ… **Open in browser**: http://localhost:8501

---

## ğŸ¯ Verify Everything is Working

### Check Backend Health
```bash
curl http://localhost:8000/health
# Should return: {"status": "ok"}
```

### Check Frontend Connection
1. Open http://localhost:8501
2. You should see the Transliteration Tutor app
3. No "API Connection Error" message

### Test a Translation
1. In the app, type: "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€"
2. Click "Detect Language" â†’ Should detect Cyrillic
3. Confirm language
4. Select target: "Latin"
5. Click "Transliterate" â†’ Should see "Privet mir"

---

## ğŸ“ System Architecture

```
transliteration-llm/
â”‚
â”œâ”€â”€ backend/                    # FastAPI Server
â”‚   â”œâ”€â”€ main.py                 # Main application
â”‚   â”œâ”€â”€ requirements.txt        # Backend dependencies
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.py           # API endpoints
â”‚   â”‚   â””â”€â”€ chat.py             # Chat functionality
â”‚   â”œâ”€â”€ llm/                    # LLM integration
â”‚   â”œâ”€â”€ ocr/                    # OCR processing
â”‚   â”‚   â””â”€â”€ language_detection.py
â”‚   â”œâ”€â”€ transliteration/        # Core logic
â”‚   â””â”€â”€ tests/                  # Test suite
â”‚
â”œâ”€â”€ frontend/                   # Streamlit Web App
â”‚   â”œâ”€â”€ app.py                  # Main app
â”‚   â”œâ”€â”€ requirements.txt        # Frontend dependencies
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ api_client.py       # Backend communication
â”‚   â”‚   â”œâ”€â”€ session_manager.py  # Session handling
â”‚   â”‚   â””â”€â”€ ui_components.py    # UI widgets
â”‚   â”œâ”€â”€ pages/                  # Future multi-page
â”‚   â”œâ”€â”€ README.md               # Frontend docs
â”‚   â””â”€â”€ QUICKSTART.md           # Quick start
â”‚
â””â”€â”€ Documentation/              # Guides & docs
    â”œâ”€â”€ START_HERE.md
    â”œâ”€â”€ LANGUAGE_DETECTION_README.md
    â””â”€â”€ ... (10+ documentation files)
```

---

## ğŸ”Œ API Endpoints Overview

### Language Detection
```bash
POST /detect-language
# Input: text or file
# Output: detected_script, iso_code, confidence, available_scripts
```

### Language Confirmation
```bash
POST /confirm-language
# Input: detected_language, user_confirmed, corrected_language
# Output: confirmed_source_script
```

### Transliteration
```bash
POST /transliterate
# Input: text/file, source_script, target_script, context
# Output: transliteration, explanation, session_id
```

### Chat (Follow-ups)
```bash
POST /chat
# Input: session_id, message
# Output: assistant_reply
```

**Full API Docs**: http://localhost:8000/docs

---

## ğŸ¨ Frontend Features

### Main Tabs
- **âœï¸ Translate** - Single text transliteration
- **ğŸ“š History** - View past translations
- **âš¡ Batch** - Process multiple texts
- **â“ Help** - Usage guide and info

### Key Features
- âœ… Text and file input (images, PDFs)
- âœ… Automatic language detection
- âœ… User confirmation workflow
- âœ… Language correction/switching
- âœ… Batch processing with progress
- âœ… Chat for follow-up questions
- âœ… Translation history tracking
- âœ… JSON export functionality
- âœ… Settings and preferences
- âœ… Help and documentation

### Supported Scripts
10 major writing systems:
- Latin, Cyrillic, Arabic, Hebrew
- Devanagari, Greek, Han
- Hiragana, Katakana, Hangul

---

## ğŸ§ª Testing the System

### Test 1: Simple Translation
```
1. Frontend: Type "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚"
2. Detect language â†’ Should show "Cyrillic"
3. Confirm â†’ "Yes"
4. Target: "Latin"
5. Transliterate â†’ Result: "Privet"
```

### Test 2: File Upload
```
1. Frontend: Upload an image with text
2. Detect language â†’ Should OCR and detect
3. Confirm or correct language
4. Choose target script
5. Transliterate
```

### Test 3: Batch Processing
```
1. Frontend â†’ Batch tab
2. Enter texts:
   - ĞŸÑ€Ğ¸Ğ²ĞµÑ‚
   - Ù…Ø±Ø­Ø¨Ø§
   - à¤¨à¤®à¤¸à¥à¤¤à¥‡
3. Target: "Latin"
4. Process â†’ View results table
5. Download as JSON
```

### Test 4: Chat Follow-up
```
1. Complete a translation
2. Ask in chat: "Why did you transliterate it this way?"
3. Get AI explanation
```

---

## ğŸ› ï¸ Troubleshooting

### Backend Issues

**Backend won't start**
```bash
# Check if port 8000 is in use
lsof -i :8000

# Kill process if needed
kill -9 <PID>

# Try different port
python -m uvicorn main:app --port 8001
```

**Import errors**
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

**LLM not responding**
- Make sure Ollama is installed and running
- Or check LLM configuration

---

### Frontend Issues

**Streamlit won't start**
```bash
# Clear cache
streamlit cache clear

# Run with debug
streamlit run app.py --logger.level=debug
```

**API connection error**
- Check backend is running: `curl http://localhost:8000/health`
- Check API URL in `frontend/utils/api_client.py`
- Check for firewall issues

**Out of memory**
- Close other applications
- Reduce batch size
- Restart Streamlit

---

### Slow Performance

**Detection is slow**
- Check text length (too long?)
- Check API response time at http://localhost:8000/docs

**Transliteration is slow**
- LLM response time is expected (1-5 seconds)
- Check if CPU/GPU is utilized
- May need optimization

---

## ğŸ“Š Example Workflows

### Workflow 1: Language Learner
```
1. Frontend â†’ Translate tab
2. Type: "Ø£Ù‡Ù„Ø§ ÙˆØ³Ù‡Ù„Ø§" (Arabic)
3. Detect language â†’ "Arabic (100%)"
4. Select target: "Latin"
5. Transliterate â†’ See romanization
6. Read explanation â†’ Learn about Arabic
7. Ask questions in chat â†’ Get context
```

### Workflow 2: Researcher
```
1. Frontend â†’ Batch tab
2. Upload list of names (Cyrillic)
3. Batch transliterate to Latin
4. Download results as JSON
5. Use in research paper
```

### Workflow 3: Content Creator
```
1. Frontend â†’ Upload PDF
2. OCR extracts text in multiple scripts
3. Transliterate to target audience script
4. Export results
5. Use in content
```

---

## ğŸ” Security Notes

- No sensitive data stored locally
- All API calls can be HTTPS (with proper setup)
- File uploads are temporary
- No authentication needed (add as needed)
- Input validation on all endpoints

---

## ğŸ“¦ Dependencies Overview

### Backend
- **FastAPI** - Web framework
- **Pydantic** - Data validation
- **Tesseract** - OCR
- **Ollama** - LLM inference
- **python-dotenv** - Environment variables

### Frontend
- **Streamlit** - Web app framework
- **requests** - HTTP client
- **python-dateutil** - Date utilities

---

## ğŸš€ Deployment (Optional)

### Production Setup

**Backend**
```bash
# Use Gunicorn + Uvicorn for production
pip install gunicorn
gunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker
```

**Frontend**
```bash
# Streamlit Cloud or Docker
# See Streamlit documentation for deployment
```

**Using Docker**
```bash
# Create Dockerfile for backend
# Create Dockerfile for frontend
# Use docker-compose to orchestrate
```

---

## ğŸ“ˆ Performance Benchmarks

| Operation | Time | Notes |
|-----------|------|-------|
| Detection | <1s | Based on text length |
| Transliteration | 1-5s | LLM dependent |
| Batch (10 items) | 15-30s | Sequential |
| Batch (100 items) | 2-5 min | Large batch |
| File upload | <2s | Size dependent |

---

## ğŸ“ Learning Resources

### In-App Help
- Frontend: Help tab with full guide
- API: http://localhost:8000/docs (interactive)

### Documentation
- Backend: `backend/api/LANGUAGE_DETECTION.md`
- Frontend: `frontend/README.md`
- System: `START_HERE.md`

### Code Examples
- API: `backend/tests/test_language_detection.py`
- Frontend: `frontend/app.py` (well-commented)

---

## âœ… Checklist: System Ready?

- [ ] Backend running on http://localhost:8000
- [ ] Frontend running on http://localhost:8501
- [ ] API health check passes
- [ ] Frontend connects to backend (no error)
- [ ] Test translation works
- [ ] Batch processing works
- [ ] History tracking works
- [ ] Export functionality works

---

## ğŸ¯ Next Steps

1. **Explore the Frontend**
   - Try different translations
   - Experiment with file uploads
   - Test batch processing

2. **Read Documentation**
   - Frontend: `frontend/README.md`
   - Backend: `backend/api/LANGUAGE_DETECTION.md`

3. **Test the API**
   - Open http://localhost:8000/docs
   - Try endpoints interactively

4. **Customize as Needed**
   - Change API URL if needed
   - Adjust UI styling
   - Add new features

---

## ğŸ“ Support

1. **Quick Start**: `frontend/QUICKSTART.md`
2. **Full Guide**: `frontend/README.md`
3. **API Docs**: http://localhost:8000/docs
4. **System Guide**: `START_HERE.md`

---

## ğŸ‰ You're All Set!

The complete Transliteration LLM system is now running!

**Backend API**: http://localhost:8000  
**Frontend GUI**: http://localhost:8501  
**API Docs**: http://localhost:8000/docs

Start transliterating! ğŸŒ

---

**Last Updated**: February 7, 2026  
**Status**: âœ… READY TO USE
